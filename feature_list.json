[
  {
    "_metadata": true,
    "description": "Active feature tasks for Editorial Assistant v3.5+",
    "archive_reference": "planning/archive/feature_list_v3.0_completed.json",
    "last_updated": "2026-01-23"
  },
  {
    "id": "backlog.1",
    "name": "Assess project rename to cardigan-editorial-assistant",
    "sprint": "backlog",
    "status": "pending",
    "agent": "orchestrator",
    "priority": "low",
    "description": "Audit what needs to change to rename project from 'ai-editorial-assistant-v3' to 'cardigan-editorial-assistant'. Less clunky, more distinctive branding. Assessment should identify: git repo rename, package.json changes, Python package names, hardcoded references in code/docs, MCP server registration name, deployment configs, any external integrations referencing the old name.",
    "files": [
      "package.json",
      "web/package.json",
      "mcp_server/server.py",
      "docs/",
      "CLAUDE.md"
    ],
    "exit_criteria": [
      "Complete inventory of files/configs requiring changes",
      "Risk assessment for breaking changes",
      "Recommended migration steps documented",
      "Decision on whether to do in-place rename or fresh repo"
    ],
    "source": "User request 2026-01-12"
  },
  {
    "id": "backlog.2",
    "name": "Content Calendar bulk scheduling interface",
    "sprint": "backlog",
    "status": "pending",
    "agent": "orchestrator",
    "priority": "medium",
    "description": "Design and implement interface for bulk Content Calendar task creation. User workflow: paste list of videos with target days (e.g., 'Midshow 1211 - Cia Siab Inc. - Thursday') → system looks up Media IDs, determines required platforms, checks editing status → creates Content Calendar entries in 'All Tasks' table linked to SST records with publish date/time and due date (2 weeks prior). Reference existing automation: /Users/mriechers/Developer/the-lodge/workflow-automation/airtable-pbswi-automations/scripts/content-calendar-automation.js. SAFETY ARCHITECTURE: Controlled Airtable write access with strict guardrails - (1) scope-limited to Content Calendar/All Tasks table ONLY, (2) append-only operations (CREATE, never UPDATE/DELETE), (3) API-level or code-level enforcement of these constraints, (4) explicit user confirmation before any write.",
    "files": [
      "web/src/pages/Schedule.tsx",
      "api/routers/schedule.py",
      "api/services/airtable.py"
    ],
    "exit_criteria": [
      "Research: Document All Tasks table schema and required fields",
      "Research: Map platform determination logic from SST fields",
      "Research: Understand content-calendar-automation.js patterns",
      "Design: UX mockup for bulk input → preview → confirm flow",
      "Design: Decide on Airtable write policy (agent writes vs human confirms)",
      "Implementation: Working bulk scheduling with editing status visibility"
    ],
    "source": "User request 2026-01-12",
    "research_refs": [
      "/Users/mriechers/Developer/the-lodge/workflow-automation/airtable-pbswi-automations/scripts/content-calendar-automation.js",
      "docs/AIRTABLE_CHEATSHEET.md"
    ]
  },
  {
    "id": "backlog.3",
    "name": "Cloudflare Tunnel for remote access",
    "sprint": "backlog",
    "status": "pending",
    "agent": "orchestrator",
    "priority": "medium",
    "description": "Configure Cloudflare Tunnel to expose API (port 8000) and web dashboard (port 3000) for secure remote access. Use Cloudflare Access for email-based authentication without requiring application-level auth changes. Enables remote MCP access from Claude Desktop on different machines. Bridge item between V3.5 feature work and V4.0 deployment - allows remote testing without full production hardening.",
    "files": [
      "scripts/start.sh",
      "docs/REMOTE_ACCESS.md"
    ],
    "exit_criteria": [
      "cloudflared installed and tunnel created",
      "API and web dashboard accessible via tunnel URL",
      "Cloudflare Access configured with email allowlist",
      "Documentation for setup and usage",
      "Optional: MCP server exposed for remote Claude Desktop"
    ],
    "source": "User request 2026-01-14",
    "notes": "Tactical infrastructure task, not a product feature. Can be done independently of sprint work. See planning/DESIGN_4.0.md Part 6 for detailed setup instructions."
  },
  {
    "id": "backlog.4",
    "name": "SEMRush keyword report upload and enrichment",
    "sprint": "backlog",
    "status": "pending",
    "agent": "orchestrator",
    "priority": "medium",
    "description": "Add ability to upload a SEMRush CSV keyword report on the Job Detail page. Upload saves raw CSV to OUTPUT/{media_id}/semrush/ for permanent storage (paid data worth preserving). After upload, automatically trigger a revised keyword report that cross-references AI-suggested keywords with real search volume, keyword difficulty, and competition data from SEMRush. This is an optional enrichment step - jobs work fine without it, but SEMRush data produces better-informed keyword recommendations.",
    "files": [
      "api/routers/jobs.py",
      "api/services/worker.py",
      "web/src/pages/JobDetail.tsx",
      ".claude/agents/seo.md"
    ],
    "exit_criteria": [
      "Upload button on Job Detail page for CSV files",
      "API endpoint POST /api/jobs/{job_id}/semrush accepts CSV upload",
      "Raw CSV saved to OUTPUT/{media_id}/semrush/ folder",
      "SEO agent re-runs keyword report with SEMRush data as additional context",
      "Revised keyword report saved as new version (keyword_report_v2.md)",
      "UI shows SEMRush data status (none / uploaded / report updated)",
      "Works as optional step - no SEMRush data required for normal pipeline"
    ],
    "source": "User request 2026-01-29",
    "notes": "No SEMRush API access - user runs reports manually and uploads CSV. Design keeps SEMRush as enrichment layer, not a dependency. Raw CSV preserved because it's paid data worth referencing later."
  }
]
